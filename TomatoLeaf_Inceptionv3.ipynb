{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TomatoLeaf_Inception.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1P9Gy69HhT4Kb5ONN4fn1hN2jcM5hMLx0",
      "authorship_tag": "ABX9TyPFOkWXoMNTBY/AO63SvwW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khawaritzmi/Deep-Learning/blob/master/TomatoLeaf_Inceptionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVU-veG7iiJ",
        "colab_type": "code",
        "outputId": "a7b6c692-945a-4300-e6b1-7616da89482c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxZ8C1L27kSi",
        "colab_type": "code",
        "outputId": "71f09cb9-a278-47a9-93fd-7d7d06d952ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/Tomato_Leaf_Dataset/Tomato_Leaf/lambace\"\n",
        "!ls \"/content/drive/My Drive/Tomato_Leaf_Dataset/Tomato_Leaf/lambace\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Tomato_Leaf_Dataset/Tomato_Leaf/lambace\n",
            "Tomato___Bacterial_spot  Tomato___Leaf_Mold\n",
            "Tomato___Early_blight\t Tomato___Septoria_leaf_spot\n",
            "Tomato___Late_blight\t Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ero93w20xRx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ca2c7daf-382a-4847-d000-45ba4e3d9326"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us0lUchYuRRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2751372d-e65e-4ab9-c812-59d5ec427039"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import keras\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from os import listdir\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf-z6EN5uhoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((299, 299))\n",
        "image_size = 0\n",
        "directory_root = \"/content/drive/My Drive/Tomato_Leaf_Dataset/Tomato_Leaf/\"\n",
        "width=299\n",
        "height=299\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKCLlFR8QrbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9H3qRcOvp1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kApH0mf30KOp",
        "colab_type": "code",
        "outputId": "95706e57-586c-47fa-88f2-ed12a9271583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    %time print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
            "[INFO] Processing Tomato___Late_blight ...\n",
            "[INFO] Processing Tomato___Leaf_Mold ...\n",
            "[INFO] Processing Tomato___Bacterial_spot ...\n",
            "[INFO] Processing Tomato___Early_blight ...\n",
            "[INFO] Image loading completed\n",
            "CPU times: user 118 µs, sys: 38 µs, total: 156 µs\n",
            "Wall time: 160 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxP2lNkZ2NfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed5oQ92sNaS7",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLt9mm6n0iBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysnVFUpd0kue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6gXeXTP0l02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq_708WI0u76",
        "colab_type": "text"
      },
      "source": [
        "**Arsitektur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcFABSYE0tFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "fcd0e000-a895-4eaf-b8bd-73853090f9b4"
      },
      "source": [
        "base_model = InceptionV3(weights=None, include_top=False, input_tensor=Input(shape = (width, height, depth)))\n",
        "\n",
        "x = base_model.output\n",
        "output = BatchNormalization()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKS25Yaq02EE",
        "colab_type": "code",
        "outputId": "5d682821-2677-4539-c670-6275390edf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            6150        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,907,110\n",
            "Trainable params: 23,872,678\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxg4hb0B04h9",
        "colab_type": "code",
        "outputId": "18d99f49-ba37-413b-be21-c52187fa322d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "[INFO] training network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnkYyhsR2PMj",
        "colab_type": "code",
        "outputId": "ccd68d92-3a43-4aad-db40-b2038d338628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 41s 1s/step - loss: 0.5359 - acc: 0.8268 - val_loss: 4.2747 - val_acc: 0.7333\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 18s 630ms/step - loss: 0.4536 - acc: 0.8467 - val_loss: 4.0413 - val_acc: 0.7368\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 18s 625ms/step - loss: 0.4038 - acc: 0.8454 - val_loss: 0.8881 - val_acc: 0.8368\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.3583 - acc: 0.8603 - val_loss: 1.2861 - val_acc: 0.7833\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 18s 617ms/step - loss: 0.3737 - acc: 0.8668 - val_loss: 4.2540 - val_acc: 0.7340\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.3736 - acc: 0.8654 - val_loss: 4.2559 - val_acc: 0.7333\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.3155 - acc: 0.8739 - val_loss: 4.0333 - val_acc: 0.7403\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.3391 - acc: 0.8625 - val_loss: 3.9724 - val_acc: 0.7340\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.3278 - acc: 0.8707 - val_loss: 4.0709 - val_acc: 0.7375\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.3696 - acc: 0.8630 - val_loss: 4.4575 - val_acc: 0.7208\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.3024 - acc: 0.8772 - val_loss: 3.4611 - val_acc: 0.7438\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.2653 - acc: 0.8918 - val_loss: 1.6031 - val_acc: 0.7882\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.2545 - acc: 0.8936 - val_loss: 0.8790 - val_acc: 0.8042\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 18s 615ms/step - loss: 0.2452 - acc: 0.9046 - val_loss: 0.4335 - val_acc: 0.8535\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.2617 - acc: 0.9026 - val_loss: 1.0670 - val_acc: 0.8021\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 18s 604ms/step - loss: 0.2442 - acc: 0.9013 - val_loss: 0.3488 - val_acc: 0.8861\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.1920 - acc: 0.9230 - val_loss: 0.5919 - val_acc: 0.8444\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 17s 603ms/step - loss: 0.1971 - acc: 0.9225 - val_loss: 0.7268 - val_acc: 0.8306\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.1840 - acc: 0.9263 - val_loss: 1.3047 - val_acc: 0.7924\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.2012 - acc: 0.9218 - val_loss: 0.2698 - val_acc: 0.8868\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.1881 - acc: 0.9253 - val_loss: 0.3877 - val_acc: 0.8632\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 17s 601ms/step - loss: 0.1665 - acc: 0.9369 - val_loss: 0.7133 - val_acc: 0.8167\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.1781 - acc: 0.9303 - val_loss: 0.3061 - val_acc: 0.8986\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 18s 618ms/step - loss: 0.1575 - acc: 0.9405 - val_loss: 0.3717 - val_acc: 0.8778\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 18s 614ms/step - loss: 0.1750 - acc: 0.9293 - val_loss: 0.4284 - val_acc: 0.8667\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 18s 630ms/step - loss: 0.1332 - acc: 0.9478 - val_loss: 0.5480 - val_acc: 0.8514\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 17s 593ms/step - loss: 0.1450 - acc: 0.9445 - val_loss: 1.0677 - val_acc: 0.8167\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.1501 - acc: 0.9407 - val_loss: 0.6143 - val_acc: 0.8299\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.1615 - acc: 0.9400 - val_loss: 0.2256 - val_acc: 0.9257\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.1300 - acc: 0.9496 - val_loss: 0.3060 - val_acc: 0.9035\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 18s 605ms/step - loss: 0.1373 - acc: 0.9480 - val_loss: 0.4982 - val_acc: 0.8674\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 18s 632ms/step - loss: 0.1331 - acc: 0.9502 - val_loss: 0.2378 - val_acc: 0.9076\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 18s 619ms/step - loss: 0.1355 - acc: 0.9529 - val_loss: 0.3711 - val_acc: 0.8861\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.1211 - acc: 0.9566 - val_loss: 0.2625 - val_acc: 0.9229\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.0982 - acc: 0.9635 - val_loss: 0.7866 - val_acc: 0.8250\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.1127 - acc: 0.9598 - val_loss: 0.6092 - val_acc: 0.8403\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 18s 618ms/step - loss: 0.0943 - acc: 0.9644 - val_loss: 0.5649 - val_acc: 0.8889\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.1211 - acc: 0.9548 - val_loss: 0.3108 - val_acc: 0.8944\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.1078 - acc: 0.9644 - val_loss: 0.3610 - val_acc: 0.8944\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0998 - acc: 0.9637 - val_loss: 0.7801 - val_acc: 0.8181\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.1074 - acc: 0.9581 - val_loss: 0.4315 - val_acc: 0.8597\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0877 - acc: 0.9686 - val_loss: 0.4570 - val_acc: 0.8833\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.1043 - acc: 0.9598 - val_loss: 0.5886 - val_acc: 0.8403\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0990 - acc: 0.9639 - val_loss: 0.4090 - val_acc: 0.8847\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0735 - acc: 0.9723 - val_loss: 0.2415 - val_acc: 0.9250\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0910 - acc: 0.9662 - val_loss: 0.3942 - val_acc: 0.8972\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 18s 614ms/step - loss: 0.0765 - acc: 0.9737 - val_loss: 0.3756 - val_acc: 0.8944\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0879 - acc: 0.9705 - val_loss: 0.5608 - val_acc: 0.8833\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0758 - acc: 0.9743 - val_loss: 0.5984 - val_acc: 0.9069\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0729 - acc: 0.9750 - val_loss: 0.5788 - val_acc: 0.9014\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0861 - acc: 0.9639 - val_loss: 0.1489 - val_acc: 0.9444\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0774 - acc: 0.9732 - val_loss: 0.6580 - val_acc: 0.8667\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 18s 617ms/step - loss: 0.0763 - acc: 0.9745 - val_loss: 0.9250 - val_acc: 0.8222\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 18s 614ms/step - loss: 0.0712 - acc: 0.9732 - val_loss: 0.5365 - val_acc: 0.9146\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0818 - acc: 0.9721 - val_loss: 0.2987 - val_acc: 0.9125\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0689 - acc: 0.9728 - val_loss: 0.9599 - val_acc: 0.8319\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 18s 617ms/step - loss: 0.0714 - acc: 0.9738 - val_loss: 0.3233 - val_acc: 0.9042\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0557 - acc: 0.9800 - val_loss: 0.5181 - val_acc: 0.8660\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0855 - acc: 0.9688 - val_loss: 0.2345 - val_acc: 0.9292\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.0719 - acc: 0.9770 - val_loss: 0.4743 - val_acc: 0.9028\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0799 - acc: 0.9718 - val_loss: 0.3998 - val_acc: 0.9007\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 18s 629ms/step - loss: 0.0531 - acc: 0.9804 - val_loss: 0.4244 - val_acc: 0.8938\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 18s 627ms/step - loss: 0.0728 - acc: 0.9732 - val_loss: 0.3505 - val_acc: 0.9104\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0642 - acc: 0.9759 - val_loss: 0.2344 - val_acc: 0.9389\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0525 - acc: 0.9806 - val_loss: 0.2470 - val_acc: 0.9306\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 18s 621ms/step - loss: 0.0638 - acc: 0.9765 - val_loss: 0.7656 - val_acc: 0.8493\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0619 - acc: 0.9766 - val_loss: 0.4702 - val_acc: 0.8778\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0684 - acc: 0.9770 - val_loss: 0.5104 - val_acc: 0.8667\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0607 - acc: 0.9763 - val_loss: 0.4386 - val_acc: 0.9056\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 18s 613ms/step - loss: 0.0734 - acc: 0.9731 - val_loss: 0.5479 - val_acc: 0.8646\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0666 - acc: 0.9775 - val_loss: 0.3343 - val_acc: 0.9132\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0499 - acc: 0.9829 - val_loss: 0.3712 - val_acc: 0.9035\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 18s 616ms/step - loss: 0.0658 - acc: 0.9771 - val_loss: 0.6619 - val_acc: 0.8535\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0605 - acc: 0.9806 - val_loss: 0.2835 - val_acc: 0.9306\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0446 - acc: 0.9829 - val_loss: 0.2389 - val_acc: 0.9375\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.0520 - acc: 0.9827 - val_loss: 0.2470 - val_acc: 0.9201\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 18s 618ms/step - loss: 0.0717 - acc: 0.9714 - val_loss: 0.6655 - val_acc: 0.8639\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 18s 612ms/step - loss: 0.0679 - acc: 0.9763 - val_loss: 0.5332 - val_acc: 0.9125\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.0522 - acc: 0.9824 - val_loss: 1.0384 - val_acc: 0.8521\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 18s 605ms/step - loss: 0.0427 - acc: 0.9819 - val_loss: 0.6487 - val_acc: 0.8618\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 18s 614ms/step - loss: 0.0414 - acc: 0.9869 - val_loss: 0.3195 - val_acc: 0.9056\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.0555 - acc: 0.9813 - val_loss: 0.2747 - val_acc: 0.9139\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0420 - acc: 0.9855 - val_loss: 0.3223 - val_acc: 0.9063\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 17s 603ms/step - loss: 0.0360 - acc: 0.9879 - val_loss: 0.3779 - val_acc: 0.9167\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.0604 - acc: 0.9786 - val_loss: 0.4974 - val_acc: 0.8847\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0628 - acc: 0.9772 - val_loss: 0.4048 - val_acc: 0.8847\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 18s 607ms/step - loss: 0.0578 - acc: 0.9779 - val_loss: 0.6573 - val_acc: 0.8611\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0471 - acc: 0.9828 - val_loss: 0.2384 - val_acc: 0.9340\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0500 - acc: 0.9804 - val_loss: 0.3779 - val_acc: 0.9347\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 18s 608ms/step - loss: 0.0315 - acc: 0.9887 - val_loss: 0.3028 - val_acc: 0.9458\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.0309 - acc: 0.9878 - val_loss: 0.2333 - val_acc: 0.9424\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 18s 626ms/step - loss: 0.0392 - acc: 0.9856 - val_loss: 0.1252 - val_acc: 0.9646\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 18s 620ms/step - loss: 0.0515 - acc: 0.9833 - val_loss: 0.0855 - val_acc: 0.9729\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0464 - acc: 0.9849 - val_loss: 0.3024 - val_acc: 0.9201\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0447 - acc: 0.9845 - val_loss: 0.1998 - val_acc: 0.9368\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0356 - acc: 0.9871 - val_loss: 0.0851 - val_acc: 0.9750\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 18s 610ms/step - loss: 0.0448 - acc: 0.9836 - val_loss: 0.1882 - val_acc: 0.9486\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 18s 611ms/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.3955 - val_acc: 0.9000\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 18s 609ms/step - loss: 0.0556 - acc: 0.9799 - val_loss: 0.3835 - val_acc: 0.8944\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 18s 606ms/step - loss: 0.0422 - acc: 0.9826 - val_loss: 0.2425 - val_acc: 0.9479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCpstKDg2WEu",
        "colab_type": "code",
        "outputId": "dee9c1bb-bfce-4f35-fcb3-6d2371008487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240/240 [==============================] - 1s 4ms/step\n",
            "Test Accuracy: 94.79166785875957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yENMNlio2XB9",
        "colab_type": "code",
        "outputId": "f901d1d4-9525-4635-bada-fc80d18cf5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMY77L8LoLX0TLUCuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURSLo0KtKIpicf4/Wq4fEFnRqKkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}