{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNeXt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a9VpMljxeANGJItQhKFpDNN5oy4MEKku",
      "authorship_tag": "ABX9TyMGsb95pftotkPVPzoVaqpH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khawaritzmi/Deep-Learning/blob/master/ResNeXt50_CocoaBeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAnpq_mCsKEo",
        "colab_type": "code",
        "outputId": "6663ceb8-0374-4370-ee78-b2bace8d1418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UePMugGOu9gt",
        "colab_type": "text"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Dataset Coklat/Dataset Coklat/Cocoa Beans\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOhIDlFyy7L",
        "colab_type": "code",
        "outputId": "58471183-f72d-42e7-c749-eca4f8d8fdb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijwcn6-3y7ef",
        "colab_type": "code",
        "outputId": "2e8c285d-ff50-4034-91af-95b1a4f6efba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import keras\n",
        "\n",
        "from keras_applications.resnext import ResNeXt50\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from os import listdir\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRPhmNJZzLzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = \"/content/drive/My Drive/Dataset Coklat/Dataset Coklat\"\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J7CFzol0Rgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsUK1kfd0Zug",
        "colab_type": "code",
        "outputId": "6ed0da27-100a-46a0-df28-4aa19d9679f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    %time print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Unfermented_Cocoa ...\n",
            "[INFO] Processing Moldy_Cocoa ...\n",
            "[INFO] Processing Fermented_Cocoa ...\n",
            "[INFO] Processing Bean_Fraction_Cocoa ...\n",
            "[INFO] Processing Broken_Beans_Cocoa ...\n",
            "[INFO] Processing Whole_Beans_Cocoa ...\n",
            "[INFO] Image loading completed\n",
            "CPU times: user 453 µs, sys: 0 ns, total: 453 µs\n",
            "Wall time: 552 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9VPb2-40eAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = len(image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diKHTyxF0ept",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LcO3o6e0gjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5PyNRU20jO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wBoh_-20oxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuoCFBDG0uHf",
        "colab_type": "code",
        "outputId": "071cf731-7f4c-430a-ef51-d6e7d04639a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "#base_model = ResNeXt50(weights= None, include_top=False, input_tensor=Input(shape = (width, height, depth)))\n",
        "base_model = ResNeXt50(input_tensor=Input(shape = (width, height, depth)), include_top = False, weights = None, \n",
        "        backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(n_classes, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pKGE_LW1Evz",
        "colab_type": "code",
        "outputId": "178c06e7-944a-4d2d-ae24-f1a94cc3a9c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9408        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 56, 56, 128)  0           conv2_block1_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 128)  0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16384       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 56, 56, 128)  0           conv2_block2_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 128)  0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  32768       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 128)  0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (DepthwiseC (None, 56, 56, 512)  4608        conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 56, 56, 32, 4 0           conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_reduce (Lambda)  (None, 56, 56, 32, 4 0           reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 56, 56, 128)  0           conv2_block3_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 128)  512         reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 128)  0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  32768       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 56, 56, 256)  65536       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 56, 56, 256)  1024        conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 56, 56, 256)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 58, 58, 256)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 28, 28, 32, 8 0           conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 28, 28, 256)  0           conv3_block1_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 256)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131072      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 256)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 28, 28, 32, 8 0           conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 28, 28, 256)  0           conv3_block2_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 256)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 256)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 28, 28, 32, 8 0           conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 28, 28, 256)  0           conv3_block3_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 256)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 256)  131072      conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 256)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 256)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (DepthwiseC (None, 28, 28, 2048) 18432       conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 28, 28, 32, 8 0           conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_reduce (Lambda)  (None, 28, 28, 32, 8 0           reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 28, 28, 256)  0           conv3_block4_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 256)  1024        reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 256)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  131072      conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 28, 28, 512)  262144      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 28, 28, 512)  2048        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 28, 28, 512)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 30, 30, 512)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_16 (Reshape)            (None, 14, 14, 512)  0           conv4_block1_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 512)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 512)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_17 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 14, 14, 512)  0           conv4_block2_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 512)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 512)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_20 (Reshape)            (None, 14, 14, 512)  0           conv4_block3_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 512)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 512)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 14, 14, 512)  0           conv4_block4_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 512)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 512)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_24 (Reshape)            (None, 14, 14, 512)  0           conv4_block5_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 512)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 512)  524288      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 512)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 512)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (DepthwiseC (None, 14, 14, 8192) 73728       conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_25 (Reshape)            (None, 14, 14, 32, 1 0           conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_reduce (Lambda)  (None, 14, 14, 32, 1 0           reshape_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_26 (Reshape)            (None, 14, 14, 512)  0           conv4_block6_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 512)  2048        reshape_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 512)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 524288      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 14, 14, 1024) 1048576     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 14, 14, 1024) 4096        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 14, 14, 1024) 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 16, 16, 1024) 0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_27 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_28 (Reshape)            (None, 7, 7, 1024)   0           conv5_block1_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_29 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_30 (Reshape)            (None, 7, 7, 1024)   0           conv5_block2_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 1024)   2097152     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 1024)   4096        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 1024)   0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (DepthwiseC (None, 7, 7, 32768)  294912      conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_31 (Reshape)            (None, 7, 7, 32, 32, 0           conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_reduce (Lambda)  (None, 7, 7, 32, 32) 0           reshape_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_32 (Reshape)            (None, 7, 7, 1024)   0           conv5_block3_2_reduce[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 1024)   4096        reshape_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 1024)   0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   2097152     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            6150        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,152,454\n",
            "Trainable params: 25,084,230\n",
            "Non-trainable params: 68,224\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbShCUwk1Lhy",
        "colab_type": "code",
        "outputId": "654151c7-427b-4140-cad3-805f781e2d2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "[INFO] training network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbgPWzdR4B12",
        "colab_type": "code",
        "outputId": "2314b191-ad6f-4232-ab92-fe5ef211ea96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "15/15 [==============================] - 38s 3s/step - loss: 1.1764 - acc: 0.7926 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.5297 - acc: 0.8437 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.4440 - acc: 0.8458 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.4859 - acc: 0.8428 - val_loss: 4.4713 - val_acc: 0.7209\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.4301 - acc: 0.8564 - val_loss: 3.9913 - val_acc: 0.7331\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.3134 - acc: 0.8653 - val_loss: 4.3227 - val_acc: 0.7209\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3550 - acc: 0.8625 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3595 - acc: 0.8575 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3388 - acc: 0.8704 - val_loss: 4.2865 - val_acc: 0.7222\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3540 - acc: 0.8715 - val_loss: 3.7823 - val_acc: 0.7209\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2704 - acc: 0.8729 - val_loss: 0.8531 - val_acc: 0.7710\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2999 - acc: 0.8774 - val_loss: 1.1868 - val_acc: 0.7412\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3356 - acc: 0.8654 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3140 - acc: 0.8644 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3420 - acc: 0.8674 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.3061 - acc: 0.8726 - val_loss: 4.2053 - val_acc: 0.7222\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2875 - acc: 0.8768 - val_loss: 3.9986 - val_acc: 0.7263\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3202 - acc: 0.8715 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3822 - acc: 0.8774 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.3562 - acc: 0.8657 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2608 - acc: 0.8782 - val_loss: 4.4746 - val_acc: 0.7209\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2604 - acc: 0.8804 - val_loss: 4.4011 - val_acc: 0.7209\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2653 - acc: 0.8795 - val_loss: 3.0770 - val_acc: 0.7344\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2297 - acc: 0.8933 - val_loss: 1.5765 - val_acc: 0.7832\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2325 - acc: 0.8938 - val_loss: 0.5135 - val_acc: 0.8482\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2022 - acc: 0.9071 - val_loss: 0.4182 - val_acc: 0.8320\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2824 - acc: 0.8796 - val_loss: 0.3874 - val_acc: 0.8157\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2385 - acc: 0.9017 - val_loss: 0.4987 - val_acc: 0.8360\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2415 - acc: 0.8935 - val_loss: 0.3055 - val_acc: 0.8631\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2119 - acc: 0.9054 - val_loss: 0.2723 - val_acc: 0.8713\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2156 - acc: 0.8959 - val_loss: 0.3402 - val_acc: 0.8401\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2109 - acc: 0.9069 - val_loss: 0.3797 - val_acc: 0.8537\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.2038 - acc: 0.9118 - val_loss: 0.2236 - val_acc: 0.9038\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2103 - acc: 0.9097 - val_loss: 0.3587 - val_acc: 0.8496\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1865 - acc: 0.9169 - val_loss: 0.2904 - val_acc: 0.8780\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1900 - acc: 0.9200 - val_loss: 0.2834 - val_acc: 0.8889\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.1722 - acc: 0.9295 - val_loss: 0.2896 - val_acc: 0.8808\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1521 - acc: 0.9343 - val_loss: 0.6430 - val_acc: 0.8103\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1575 - acc: 0.9367 - val_loss: 0.7005 - val_acc: 0.7927\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1850 - acc: 0.9257 - val_loss: 1.1807 - val_acc: 0.7507\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1741 - acc: 0.9216 - val_loss: 1.0318 - val_acc: 0.7656\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.1572 - acc: 0.9323 - val_loss: 1.4676 - val_acc: 0.7507\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1477 - acc: 0.9398 - val_loss: 1.6408 - val_acc: 0.7425\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 17s 1s/step - loss: 0.1760 - acc: 0.9292 - val_loss: 1.9800 - val_acc: 0.7317\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1491 - acc: 0.9365 - val_loss: 1.5572 - val_acc: 0.7371\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.2295 - acc: 0.9143 - val_loss: 3.5251 - val_acc: 0.7290\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1439 - acc: 0.9382 - val_loss: 4.2073 - val_acc: 0.7222\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1492 - acc: 0.9389 - val_loss: 1.7384 - val_acc: 0.7439\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1610 - acc: 0.9307 - val_loss: 1.7253 - val_acc: 0.7602\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 16s 1s/step - loss: 0.1521 - acc: 0.9346 - val_loss: 1.2954 - val_acc: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlZWThm94cCI",
        "colab_type": "code",
        "outputId": "6bf38524-b829-4922-f913-42610d2e7afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123/123 [==============================] - 1s 7ms/step\n",
            "Test Accuracy: 74.7967516503683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OGcf_kY4k9X",
        "colab_type": "code",
        "outputId": "c4c5826a-5f77-4c65-8289-fa21351803f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5gU1dKH3wKJAkqSIFmJikRBBASM\niAiKBBEvSUFUzIh6VcCAkStGDBgwoIAJMV/UVfzEwBL0St4FhF0EkSwZ9nx/1AzMLjO7M7szO6ne\n55lnZrpPd1dP+HV1nTp1xDmHYRiGkbgUibYBhmEYRmQxoTcMw0hwTOgNwzASHBN6wzCMBMeE3jAM\nI8ExoTcMw0hwTOiTBBH5XEQGhbttNBGRNSJybgT2+62IXO15PUBE/htM23wcp5aI/CMiRfNrq2EE\ngwl9DOMRAe8jS0T2+LwfEMq+nHMXOudeD3fbWERE7hSROX6WVxKR/SJyarD7cs5Ndc6dHya7sl2Y\nnHNrnXNlnHOHwrF/wwiECX0M4xGBMs65MsBa4GKfZVO97UTkmOhZGZO8BZwpInVzLL8c+J9z7vco\n2JQ05Of3aL/hyGJCH4eISGcRyRCRO0RkA/CaiJQXkU9EZJOIbPW8ruGzjW84YrCI/J+ITPC0XS0i\nF+azbV0RmSMiO0XkKxF5TkTeCmB3MDY+ICI/ePb3XxGp5LP+XyLyh4hsFpG7A30+zrkM4BvgXzlW\nDQTeyMuOHDYPFpH/83l/nogsE5HtIvIsID7rThKRbzz2/S0iU0XkeM+6N4FawMeeO7LRIlJHRJxX\n5ESkuojMEpEtIpImIsN89j1ORGaIyBuez2axiLQO9BmIyFMisk5EdojIfBHp6LOuqIj8W0TSPfua\nLyI1PetOEZHZHhs2isi/PcuniMiDPvvoLCIZPu/XeH6PvwG7ROQYz52V9xhLROTSHJ/rDyIyUUQ2\nA+NEpJSI/MfzHW/3/O5KicinInJDjvP7zXd/Ru6Y0McvVYEKQG1gOPpdvuZ5XwvYAzyby/ZtgeVA\nJeAx4BURkXy0fRv4BagIjONocfUlGBuvAIYAJwDFgVEAItIEeN6z/+qe4/kVZw+v+9oiIg2B5h57\nQ/2svPuoBHwA3IN+FulAe98mwMMe+xoDNdHPBOfcv8h+V/aYn0NMAzI82/cGHhKRs33W9/C0OR6Y\nlYfN8zznW8Fzzu+KSEnPuluB/kA3oBwwFNgtImWBr4AvPDacDHyd22eSg/7ARcDxzrmD6OfTETgO\nuA94S0Sq+bRvC6wCqgDjgQlAK+BMj92jgSz0u7zSu5GINANOBD4Nwbbkxjlnjzh4AGuAcz2vOwP7\ngZK5tG8ObPV5/y1wtef1YCDNZ11pwAFVQ2mLiuRBoLTP+reAt4I8J3823uPz/jrgC8/rMcA0n3XH\nej6DcwPsuzSwAzjT83488FE+P6v/87weCPzk005QYb46wH4vARb6+w497+t4Pstj0IvCIaCsz/qH\ngSme1+OAr3zWNQH2hPD72Qo087xeDvT006a/r7051k0BHvR53xnIyHFuQ/OwYZH3uJ7Pda3PuiLo\nBbeZn+1Keuyv73k/AZgU6f9cIj3Mo49fNjnn9nrfiEhpEXnRc9u7A5gDHC+BMzo2eF8453Z7XpYJ\nsW11YIvPMoB1gQwO0sYNPq93+9hU3XffzrldwOZAx/LY9C4w0HP3MQB4IwQ7/JHTBuf7XkSqiMg0\nEcn07Pct1PMPBu9nudNn2R+o5+ol52dTUgLEtkVklIgs9YRAtqFetdeWmqi3nZNAy4Ml23cvIgNF\nZJGIbPPYcCrZPw/f9pVQQT/q+J7f+XTgShEpgl6Q3iyAnUmHCX38krPs6G1AQ6Ctc64ccJZneaBw\nTDj4E6ggIqV9ltXMpX1BbPzTd9+eY1bMY5vXgb7AeUBZ4OMC2pHTBiH7+T6Efi9NPfu9Msc+cysV\nux79LMv6LKsFZOZh01F44vGj0XMv75w7HtjuY8s64CQ/m64D6gXY7S70LslLVT9tDp+fiNQGJgMj\ngYoeG34n8OfxN7A3gF2g3+UA4Bxgt3PuxwDtDD+Y0CcOZdFb320iUgEYG+kDOuf+AFLRjrTiItIO\nuDhCNr4HdBeRDiJSHLifvH+/3wPbgJfQsM/+AtrxKXCKiPTyeNI3kl3wygL/ANtF5ETg9hzbbySA\nkDrn1gFzgYdFpKSInAZchd4VhEpZNKS2CThGRMagsXgvLwMPiEh9UU4TkYrAJ0A1EblZREqISFkR\naevZZhHQTUQqiEhV4OY8bDgWFfJNACIyBPXo/eKcywJeBZ4Q7ZQuKiLtRKSEZ/2PaLz+P5g3HzIm\n9InDk0Ap1DP6Ce1QKwwGAO3QMMqD6C32vgBt822jc24xcD3asfgnGrPNyGMbh4ZranueC2SHc+5v\noA/wCHq+9YEffJrcB7REvedP0Y5bXx4G7vGEMkb5OUR/NG6/HvgQGOuc+yoY23LwJXpOK9Dwz16y\nh0meAGYA/0X7MV4BSnnCRuehF+sNwEqgi2ebN4Ff0Vj8f9HvOSDOuSWoKP+IXuCakv2z8sco4H9o\nR/IW4FGya9Qbnv3k5+KX1Iinc8MwwoKITAeWOecifkdhJBciMhAY7pzrEG1b4g3z6I0CISKni+aP\nFxGRrkBPYGa07TISC0+fzHVoGM4IERN6o6BURdMR/wGeBq51zi2MqkVGQiEiF6Cx/o1o6M4IEQvd\nGIZhJDhBefQi0lVElosOy77Tz/raIvK1Z1jyt5J9WPshTy7tIhGZFU7jDcMwjLzJ06P3DCJZgfbG\nZ6A94v09vereNu8CnzjnXvcM2R7idMg3IvKP06JcQVGpUiVXp06dkE/EMAwjmZk/f/7fzrnK/tYF\nUzGuDToEfhWAiExDO9yW+LRpgtbPAEihAJ1xderUITU1Nb+bG4ZhJCUi8kegdcGEbk4kew5uBtmH\nZYPm1/byvL4UKOsZgAE6TDtVRH4SkUsCGDjc0yZ106ZNQZhkGIZhBEu4sm5GAZ1EZCHQCR227Z1M\nobZzrjValfBJETlqiLNz7iXnXGvnXOvKlf3eeRiGYRj5JJjQTSbZ63nUIEf9DefcejwevYiUAS5z\nzm3zrMv0PK8SkW+BFhSscJJhGIYRAsEI/TygvuhsPZnoLD1X+Dbw1One4qlXcRdaswIRKY8WINrn\nadMerWceEgcOHCAjI4O9e/fm3dhISkqWLEmNGjUoVqxYtE0xjJgjT6F3zh0UkZFo/YyiwKvOucUi\ncj+Q6pybhdamflhEHFry9XrP5o2BF0UkCw0TPeKbrRMsGRkZlC1bljp16iAB58YwkhXnHJs3byYj\nI4O6dXPOHmgYRlDzNDrnPgM+y7FsjM/r99Dqgjm3m4sWISoQe/fuNZE3AiIiVKxYEevINwz/xE0J\nBBN5Izfs92EYgYkboTcMw4gXtm6FSZNgy5ZoW6KY0AfB5s2bad68Oc2bN6dq1aqceOKJh9/v378/\n121TU1O58cYb8zzGmWeeGS5zDcOIEocOwQsvQP36cP31MHx4tC1STOiDoGLFiixatIhFixYxYsQI\nbrnllsPvixcvzsGDBwNu27p1a55++uk8jzF37txwmlwoHDp0KO9GkOvnYxiR4osvoG5d+O9/C+d4\nKSnQsiVcey2ceiqMHAnvvw/vHdV7WfiY0OeTwYMHM2LECNq2bcvo0aP55ZdfaNeuHS1atODMM89k\n+fLlAHz77bd0794dgHHjxjF06FA6d+5MvXr1sl0AypQpc7h9586d6d27N40aNWLAgAF46xF99tln\nNGrUiFatWnHjjTce3q8va9asoWPHjrRs2ZKWLVtmu4A8+uijNG3alGbNmnHnnVqbLi0tjXPPPZdm\nzZrRsmVL0tPTs9kMMHLkSKZMmQJoiYo77riDli1b8u677zJ58mROP/10mjVrxmWXXcbu3bv9fj7+\njjNw4EBmzjxSLWPAgAF89NFHBf5uDOPTT6FnT1izBgYNgs0Bp5EvOKtXQ+/ecPbZsH27CntKCkyc\nCK1aqWf/99+RO34wBJV1E0vcfDMsWhTefTZvDk8+Gfp2GRkZzJ07l6JFi7Jjxw6+//57jjnmGL76\n6iv+/e9/8/777x+1zbJly0hJSWHnzp00bNiQa6+99qjc74ULF7J48WKqV69O+/bt+eGHH2jdujXX\nXHMNc+bMoW7duvTv39+vTSeccAKzZ8+mZMmSrFy5kv79+5Oamsrnn3/ORx99xM8//0zp0qXZ4gke\nDhgwgDvvvJNLL72UvXv3kpWVxbp16/zu20vFihVZsGABoGGtYcOGAXDPPffwyiuvcMMNNxz1+bRt\n2/ao41x11VVMnDiRSy65hO3btzN37lxef/310L4EI25wDjZuhKVLYdkyWLcOhgzRMEc4+fhjuOwy\nOO00ePxxuOACGDECZsyAcPfZz52rAl+0KDzwANx2G5QqpeuOOQZee03F/uab4a08JkA8dAh27YJy\n5XJvlx/iTuhjiT59+lC0aFEAtm/fzqBBg1i5ciUiwoEDB/xuc9FFF1GiRAlKlCjBCSecwMaNG6lR\no0a2Nm3atDm8rHnz5qxZs4YyZcpQr169w3ni/fv356WXjp5s58CBA4wcOZJFixZRtGhRVqxYAcBX\nX33FkCFDKF26NAAVKlRg586dZGZmcumllwI66CgY+vXrd/j177//zj333MO2bdv4559/uOCCC476\nfAIdp1OnTlx33XVs2rSJ999/n8suu4xjjrGfZCKRkQH33w+//abivn179vXTp8O8eVChQniON3Mm\n9O2rztuXX0L58irAd94JU6fClVcG3vaff9T7r1dPLxDB8PjjKswLFkCOvzEATZvC3XfDuHHQrx9c\nfLH//WzeDAMGqNh/+SUUCXOsJe7+VfnxvCPFsccee/j1vffeS5cuXfjwww9Zs2YNnTt39rtNiRIl\nDr8uWrSo3/h1MG0CMXHiRKpUqcKvv/5KVlZW0OLtyzHHHENWVtbh9zlHJPue9+DBg5k5cybNmjVj\nypQpfPvtt37bBWLgwIG89dZbTJs2jddeey1kW43YJTUVevRQcT/jDBWyRo300bixevSdOunyTz5R\nr7ggvP8+XH65etBffAHHH6/LR43S/V9/PZx1FtSqdfS2W7dCt27w009qx003+RduXzIz9e5h1Kjc\n2951l9o2YgR07HjELi8LF0KvXrB+PTz7bPhFHixGHza2b9/OiSdqUU9vPDucNGzYkFWrVrFmzRoA\npk+fHtCOatWqUaRIEd58883DHabnnXcer7322uEY+pYtWyhbtiw1atQ4HCfft28fu3fvpnbt2ixZ\nsoR9+/axbds2vv7664B27dy5k2rVqnHgwAGmTp3qt02g44BeKJ70XL2bNGkS4qdixCoffKCiWrw4\n/PwzfP01PPcc3HADnHeeCmO7dvDMMyrKYws4lfy776rHfPrp2vnqK6ZFi8Lrr0NWFgwerM++/PUX\ndOmiXvlTT2mIadKkvI/5yivqgeeVWVO8uIZwNm7Ui4Ivb74JZ54JBw7AnDngiYKGHRP6MDF69Gju\nuusuWrRoEZEsk1KlSjFp0iS6du1Kq1atKFu2LMcdd9xR7a677jpef/11mjVrxrJlyw571V27dqVH\njx60bt2a5s2bM2HCBADefPNNnn76aU477TTOPPNMNmzYQM2aNenbty+nnnoqffv2pUWLFgHteuCB\nB2jbti3t27enUaNGAdv5Ow5AlSpVaNy4MUOGDCnIx2PECM7BI49ojLxZMxX5U08N3H74cLjqKhg/\nXsMu+eG//4X+/fWu4csv/ce469VTEU9J0WcvGRl6QVqxQr3+G2/Uu5CXXoI9ewIf8+BBmDwZzj9f\n950XrVrB7bfrxWH2bNi/Xy96AwdC27Z6kWnbNvRzDxrnXEw9WrVq5XKyZMmSo5YlIzt37nTOOZeV\nleWuvfZa98QTT0TZooKza9cuV69ePbdt27YC78t+J9Fl3z7nhgxxDpy7/HLndu8Obrs9e5w7/XTn\nypZ1LtSvcPdu5+rWda5xY+d27Mi9bVaWcz17OleihHP/+59z6enO1anjXLlyzn3//ZF2KSl6Di+/\nHHhfH32kbT74IHhb9+xxrmFD52rVcq5DB93+1ludO3Ag+H3kBlp7zK+uRl3Ycz5M6APzxBNPuGbN\nmrnGjRu7K664wu3atSvaJhWI2bNnu1q1armJEyeGZX/2O4kemzc716mTKsrYsSqqobB2rXMnnKBC\nuH178NuNGaPH/Oab4Npv3KjHOeUU56pXd65CBedSU7O3ycpy7rTTnGvaNPB5dOum2+/fH7ytzjn3\nww/OiThXurRz06aFtm1emNAbSYH9TqLD1q3OtWjhXPHizk2dmv/9fPutc0WLqtd96FDe7VeuVO+8\nf//QjjNrlipf1arq2fvj5ZcDX0BWr1axvvfe0I7r5csvnVu2LH/b5kZuQm8xesMw8s3OndC1K/z+\nu8bYr7gi720C0akT/Oc/8NFHeXfOOqfx9OLFdZtQuPhizZbJrf/giiugYkXwN6h98mTNx7/66tCO\n6+X886Fhw/xtm1/iLr3SMIzYYNcuuOgimD9fR4NeeGHB93njjZpz/+CDKuL33uu/3Ucfweef6+jT\natVCP46fQeXZKFVKO4ofeURHvnqnOThwQDtUL7rIf5pmrGIevWEYIbNnj2an/PCDDkTq2TM8+xXR\njJeBA2HMGB1slZNduzTPvWlTrScTKa67TnPan332yLKPPtI0yWuuidxxI4F59IZhhMS+fZo+mZIC\nb7yhI1HDSdGi8OqrKvreEM6YMUfWjx8Pa9dq3nkkB1LXqKE1bF55Be67D8qU0cqUtWppuCqeMI8+\nCLp06cKXX36ZbdmTTz7JtddeG3Cbzp07k5qaCkC3bt3Ytm3bUW3GjRt3OJ89EDNnzmTJkiOzL44Z\nM4avvvoqFPMNI2wcOKADkz7/XD3v3EoKFISiRVVgBw1Ssb/vPl2+fDlMmKAef8eOkTm2LzfdpCN7\n33gDVq7UgV/Dhxd8FG9hYx59EPTv359p06Zlq+Mybdo0HnssuHnOP/vss7wbBWDmzJl079798KjR\n+/3dy8Y4hw4dOlwTKDcOHjxotW5imC1b4F//gs8+0xGt+e2MDBav2ItorRjnNFRUujQE+dcrMGec\nAa1ba6dserreQQwdWjjHDifm0QdB7969+fTTTw9PMrJmzRrWr19Px44dufbaa2ndujWnnHIKYwOk\nCtSpU4e/PXVKx48fT4MGDejQocPhUsaA33K/c+fOZdasWdx+++00b96c9PR0Bg8ezHueAtdff/01\nLVq0oGnTpgwdOpR9+/YdPt7YsWNp2bIlTZs2ZdmyZUfZZOWMjVD48UctFDZ7Njz/fGRj474ULQov\nv6ylC+67D776SkM3VaoUzvFF1KtfvlzFvmfP/HX+Rpv4c5+iUKe4QoUKtGnThs8//5yePXsybdo0\n+vbti4gwfvx4KlSowKFDhzjnnHP47bffOO200/zuZ/78+UybNo1FixZx8OBBWrZsSatWrQDo1auX\n33K/PXr0oHv37vTu3Tvbvvbu3cvgwYP5+uuvadCgAQMHDuT555/n5ptvBqBSpUosWLCASZMmMWHC\nBF5++eVs21s5YyMYsrI0ffHf/4aaNdWjPv30wrXBK/ZlymgGzIgRhXv8vn21fMGGDYV/7HBhHn2Q\neMM3oGEbbz34GTNm0LJlS1q0aMHixYuzxdNz8v3333PppZdSunRpypUrR48ePQ6v+/333+nYsSNN\nmzZl6tSpLF68OFd7li9fTt26dWnQoAEAgwYNYs6cOYfX9+rVC4BWrVodLoTmy4EDBxg2bBhNmzal\nT58+h+0Otpyxd31u5CxnHOj8citnXLp0aTp16sTKlSvZtGkT77zzjpUzLiT+/ltzzkePVk92wYLC\nF3kvRYtquCgcVS5DpXhx7Sfo2lVrz8cj8fdviVKd4p49e3LLLbewYMECdu/eTatWrVi9ejUTJkxg\n3rx5lC9fnsGDBx9V0jdYciv3mx+8pY4DlTm2csZGbsydq52uf/2l6YXXXRf+STviiREj4tebB/Po\ng6ZMmTJ06dKFoUOHHvbmd+zYwbHHHstxxx3Hxo0b+fzzz3Pdx1lnncXMmTPZs2cPO3fu5OOPPz68\nLlC537Jly7Jz586j9tWwYUPWrFlDWloaoNUhO3XqFPT5WDljIxDLl2sp4RIlNDZ//fXJLfKJgAl9\nCPTv359ff/31sNA3a9aMFi1a0KhRI6644grat2+f6/YtW7akX79+NGvWjAsvvJDTfe6DA5X7vfzy\ny3n88cdp0aIF6enph5eXLFmS1157jT59+tC0aVOKFCnCiBBcDitnbPhj71715EuVgu++08mujfhH\ntBZO7NC6dWvnzT/3snTpUho3bhwli4xYYPfu3TRt2pQFCxb4rcMP9jsJBzfeqLHwjz/Ou0yAEVuI\nyHznXGt/68yjN2Ker776isaNG3PDDTcEFHmj4MyapSJ/880m8olG/HXGGknHueeeyx9//BFtM+KW\nrVvh00/h0kshUL93RgYMGQItWmghLyOxiBuPPtZCTEZsYb8P/6SkwGmn6YjWhg3hnXd0hKkvBw9q\nWd79+2H6dO2ENRKLuBD6kiVLsnnzZvszG35xzrF58+Z8pYgmKvv26SCfc87RkgFvvAFVq6qgn3UW\nLFx4pO2DD8L33+uE2PXrR89mI3LEReimRo0aZGRksGnTpmibYsQoJUuWpEaNGtE2IyZYvBgGDIBf\nf9Xc7wkTNGQzYAC89hrcdZdOVj1sGFxwATzwgHr8//pXtC03IkVcZN0YhpE3WVk6uGn0aChXTkv9\n+utU3bZN67w/84yGberX18lDypYtfJuN8GFZN4YRZr75BubNi7YV2bn/fi3Add558L//Bc6cOf54\neOIJnclp+HD44AMT+UTHPHrDCJENG+Dkk9UT9o11R5OtW6F2bRX5996zkazJiHn0hhFGxo3T6ewW\nLYLMzGhbozzzjE7UPXasH5F3Diw9NakxoTeMEFi6VEvmnnuuvv/ii+jaAyrwTz6pc7j6rZA9e7bO\nbu0z/4GRXAQl9CLSVUSWi0iaiNzpZ31tEflaRH4TkW9FpIbPukEistLzGBRO4w2jsLnjDs1geftt\nnVM02MnD9uzRi0KwkVLndKq+YKZemDRJQzd33x2gwaJFusNcSmgbiU2eQi8iRYHngAuBJkB/EclZ\nPnAC8IZz7jTgfuBhz7YVgLFAW6ANMFZEyofPfMMoPL77TmvA3HknVK4M3bqps+yZeCxXnnoKLrxQ\nxTsYpk6Fa67RbTZuDNxu926dGOT886FNmwCNPBVOWb06uIMbCUcwHn0bIM05t8o5tx+YBvTM0aYJ\n8I3ndYrP+guA2c65Lc65rcBsIM7mTzcMTV0cNUq9eM8kXnTrpmGTH37IfVvn4M039fUtt+TtWK9Z\no6WBmzfXVMh//UuP74/Jk2HTJrj33lx26K166mcCGiM5CEboTwR854zL8Czz5Vegl+f1pUBZEakY\n5LaIyHARSRWRVBsUZcQiM2ZAaqqOIi1VSpedcw4UK5Z3+ObXX1Xcx4zR6fD699dywP44dAgGDtSL\nwwcfaCfr7Nnw8MNHt923TyfJ7tQJOnTIxQCv0JtHn7SEqzN2FNBJRBYCnYBM4FCwGzvnXnLOtXbO\nta5cuXKYTDKM8LBvn44mbdYMrrzyyPIyZVRk8xL6qVPhmGO0BPCUKZq/fscd/ts+9piWI3j2We0/\nveoqLVswZgz4zBQJ6L7Wr4d77snDeO/cvib0SUswQp8J1PR5X8Oz7DDOufXOuV7OuRbA3Z5l24LZ\n1jBinUmTNOrx2GNHz1farZt664GiIocOacfthRdCxYra/qab4OmntaKkL6mpKuh9+x4pRyACL7wA\nJ52kdwLeG94DB7TKZNu2emcRkDVrNO5TsaK+jrFxM0Yh4ZzL9YHWw1kF1AWKo2GaU3K0qQQU8bwe\nD9zveV0BWA2U9zxWAxVyO16rVq2cYcQKW7Y4V768c+ef73/9smXOgXOTJvlf//XXun769CPL9uxx\nrlkz5ypVcm79el32zz/ONWjg3IknOrd589H7WbjQuRIlnOva1blDh5x77TXd7yef5HECn36qDfv2\n1ee//srrlI04BUh1AXQ1T4/eOXcQGAl8CSwFZjjnFovI/SLSw9OsM7BcRFYAVTxij3NuC/AAMM/z\nuN+zzDBihqVLtbLjySerdzx0qJYTeP11uO027RB9/HH/2zZoAPXqBQ7fvPWWlhe4+OIjy0qW1HLB\nu3bBoEFHOnpXrNAqkxUqHL2f5s1h4kRN0XzkEXjoIV3WrVseJ+eNz3sT/y18k5wEugJE62EevVHY\nDBrkXOnSzl1+uXPt2jlXrZo6v97H4MG5bz9ypHOlSqmn7svu3c6VLRt4+xdf1P336qXPt92W+3Gy\nspzr0+eIXe+9F8TJ3Xijc8ce69yvvx59a2EkFOTi0cdFmWLDiBQZGRpDv/ZazXX3snev9mFmZoLP\nHO5+6dZNO0+/+07L/nr55BNNvxwwwP92w4bBl19qds1pp8H48bkfR0TTKRcs0Brzl14axAmmp2uA\nv25dfW8efVJiQm8kNU89paGTW27JvrxkSS1aFsxEHJ07a/vPPssu9G+9BdWqQZcu/rfzCvcJJ2hu\nfjAzOx13nA50PXgQigSTSpGeDk2aaPyoYkUT+iTFat0YScv27fDii9CnD9Spk//9lCoFZ5+dPU6/\neTN8/rmmRubM1PGlQgV4/nmd5i9YypTRUsN5cugQrFqlHj3oSdqgqaTEhN5IWl56SUMrt99e8H11\n66aVBlau1PfvvqspkIHCNoVCZqbWZ/AKfd26BffoJ0zQONehoIfJGDGACb2RlOzfrxUfzzkHWrYs\n+P4uvFCfvV79W29pxKR584LvO994M258hd6bV58ffvlFp6964YXwXB2NQsOE3khK3n5bR5WGS6/q\n1YNGjVToV6/W+jcDBkR5AhCv0J98sj7XqaNXuA0bQt/XgQNw9dVQvbpOSzVxogq+ERdYZ6yRdGRl\naQTitNO06mO48GbfTJ6s76+4Inz7zhfp6VqMp6ZncLpv5k316qHta8IEnZ9w5kydozAzE0aO1Ctc\nOD9EIyKYR28kHZ9/DosXq37PQdsAACAASURBVDcfTo+7Wzd1mCdM0CJjBengDQtpaWqEtzc4vymW\nK1fCffdB797Qs6fu75134JRTtCd78eKwmm2EHxN6I6E4cABefVXr0mzb5r/N44+rk9uvX3iP3aGD\nZsQcOJC9+FnUSE8/ErYBnVQWQsu8cU5DNSVLaoEeL2XL6kCB0qXhootyL5pvRB0TeiMhyMpSJ7NJ\nE634eMcd6sCOH6+ZNV5++UUHNt18s0Y1wkmJElppoFgxdXSjinNHBkt5KVVKaz2E4tG/+ip8+61e\nHatVy76uZk2YNQv++gsuuUSn0TJiEhN6IyY4cADmzg29uKJz6li2aKEx8dKldRaohQvhrLO0hG+9\nejoL0549qlfHHaejUiPBf/6jVSn91aspVP7+G3bsyC70oKGcYIV+wwYtwnPWWXr19Mfpp2uK0U8/\naWetEZOY0BtRZ8MG9YTbt89ehiAvfvpJwyUXX6xT6r39tgp89+6a1vjRR/Dzz5o+OWqUat4HH8CI\nERp5iAT16sF550Vm3yGRM7XSizfFMhhuukmvji+9lPsw3F694NZb9QsIFC8zoooJvRFVfvwRWrWC\nefNUkO+6C5Yty3u733/X0ahr1ujo1iVLtF57Tj1q00bryXz3nYary5XTCUASnpyplV7q1oW1a7WG\nQm58/LFOq3XvvcEN223dWp///DN0W42IY0KfoGRl6f/0q6+ibYl/nNOh/506aT/fTz9pyKN0aS3d\nm5sO7dypCSDlyulkHcOH5x1vP+ssFftNm0LPLIxL0tM1pcibaeOlTh0d1ZqZx/w/t90Gp54a/EAD\nb/zehD4mMaFPQH79VYWtXz/tI4u18iZ79mjN9+uu0zBHaqrmtFetquL/yy+aNeMPbxLIypUwbdrR\n/YO5IaJT+iUFaWlw4ol6FfUlmBTLP/7QD/iaa6B48eCOZ0If05jQJxDbtmlYtWVLWL5cOwZF9P9a\n2DPI7dunWrNggXrSn3yiIdwXX9S4+pQpMHasRgjKlz+yXd++eoEaN04vWDl54QUV+Ace0KqRRgBy\nZtx4CUbovZPTnnVW8MczoY9pksW/iSu2b9fMkGBxThMfbr9dQxMjRsCDD6qAFi8ON9wAb74JAwdG\nzmaArVu1BMDMmTooadcu/+3Kl1eB797d//rnntOMvoEDNXbvdSpTUzUtsls3uPPOiJxC4pCe7v8D\nrllTr/653ebNmaPlMU89NfjjlS2rcTcT+pjEPPoY49VXVQjHjg2uQGB6unq2AweqszZvngql10u+\n7jrNZrn55siMaVm/Xo933nlaV/3KK+H//k+fp0yBDz+Er7/WcMyyZRoa/vPPwCIPWjZ98mT47Ted\n0g/0ItKnD1SpotPtBVWLPVn55x/9sv159MWLQ40auXv0330HHTuG9iGLqFe/fn3o9hqRJ9DUU9F6\nJPNUgllZzjVtqtPagXOdOjmXkRG47aRJ2va445x7+WWdNNofS5c6V7y4zg8dLv74w7lrrnGuWDG1\ntVEj5+64w7kffwxsR6gMGeJckSK6zx499Fg//hiefccFWVn5227RotynDTzrLOc6dPC/bv163fbx\nx0M/bocO+qM1ogK5TCUYdWHP+Uhmof/hB/1GXnrJuSlTVMQrVXLu00+zt1u3zrnzz9e255+v7/Pi\nwQe1/cyZBbNx7VrnRoxQ0S1e3LnrrnNuyZKC7TMQ27Y5V7Omc2XKqO1PPhmZ48Qk69c717Chc08/\nHfq277+vH9j8+f7XDxzoXI0a/tdNn67b/vJL6Mft08e5Bg1C384ICyb0ccLAgTqZ9M6d+n7pUudO\nO02/pVGjnNu3z7k331QPvnRp9eiDdfr279d9Va/u3Natodu2dq1z116rAl+smL5euzb0/YTK7Nl6\n/pddln8HN+7Ytcu51q31xM8+O/TtH3tMt922zf/6sWOdE3Fu796j111/vU4mfuBA6Me98Ub9ARtR\nwYQ+Dti82bkSJVRAfdm9Wz1ocK5qVX1u3965lStDP8a8eRoKGTYs+G2yspybPNm5kiVV4EeM0LBN\nYbJkiV7kkoJDh5zr1UuFuEULvZ05eDC0fQwf7lzFioHXT5miP6QVK45e17Sp3ibmh0ce0f3+80/+\ntjcKRG5Cb11aMcIbb2hK4jXXZF9eqpTmls+YoYkNjz56ZJRnqLRureNgJk+GlJS82+/apYOXhg3T\nvrmVK9WWWrVCP3ZBaNw4+HTuuOff/9Y6DU88oWUF/vlHhwGHQqDUSi/e+sk5M2+2bNGa86GkVfpi\nKZYxiwl9DOCc5oefcQY0a+a/TZ8+sGKFzuSW22TTeTFunF4k+vfXAl+bN/tvt2wZtG2raZv33afp\nkt4qt0aEePVVvZKPGKEDItq10+U//RTafnKWJ85JoFz677/XZxP6hMOEPgxkZcHDD2v1xfwwZ44O\ncMrpzUeC0qV14uqGDfWiUaOGFiZcsOBIm3feUe//r7+0TsyYMQW7uBhBkJKiP4Dzz9e67yJaIa1y\nZS0IFCz792stm9w8+hNP1CHCOYV+zhyttdymTf7OwYQ+ZjGhDwP/+Y/ecXfqpP9RF+Io1Bde0PEp\nfftGxr6cNG+u4Z/fftPQzLRpWlisXTvNf7/iCm2zcGGMVGJMdJYv1wqQDRpojM5buEdEb/NCEXrv\n5N+5CX3Rohp/yxm6mTNHj1eiRKhnoHiF3nLpYw4T+gKyaBHcfTf06KEjNm+6ScVy9+7gtt+0Cd5/\nXwc8lS4dWVtz0rSpXmQyM+HJJzWMM3WqlvRNSVHHz4gwu3bp6LFixbRORM4h0e3aacwuUIwtJ4HK\nE+ekbt3sHv3OnXpbl9+wDWgR/uLFzaOPQUzoC8CePer9Vqqk4dUPP9TSA++8o/9P738uN6ZM0Uk3\nCiNsE4jjj9cL1LJl2h/3+OPhn33JCMA332hRoFdfPbrSJByJ0//8c3D7C1SeOCc5JyCZO1fvBAoi\n9CJamc6EPuYwoS8Ao0fD0qXw+us6bL9IEfXuP/8c1q3TOPdnnwXePitLi3x17KhT4EWbIkWyFxgz\nCoFvvtEKk4FiZKefrl9MsOGb9HQ49litFZEbdetqJ4z31nPOHI3bey8s+aVaNRP6GMSEPp98/jk8\n+6zWkMn5H73gApg/X52m7t3VW/ZX/vubb/R/OWJEoZhsxCIpKXDmmYHj4sceqzWcgxX6tDTtxBXJ\nvZ337sEbp58zRz2TY48N7jiBMKGPSUzo88GmTTBkiBb3e/hh/23q1tW74eHDtehXvXr6Oi3tSJsX\nXtA7gcsuKxy7jRhj82atxdylS+7t2rXT0E2wVe6CGWThzaVfvVpjkL/8UrCwjRcT+pjEhD5EnNM5\nkLdu1Y7LnPM6+FKqlIr5ihWawvjGG5rWePnl8N//6pymQ4bkP8nBiHO+/Vafzz4793bt2unAqSVL\ncm+XlQWrVuXdEQvZPfqff9a0zHAIffXq2tGzb1/B92WEDRP6EHn5ZZg1Cx55RO+og6FePZg0Sf9T\nt9+ucfsLLtDp8oYPj6i5RiyTkqKhktNPz72dN26eV/gmM1MFNhihr1pVvZTVqzVsI6L1rAuKN8Vy\nw4aC78sIGyb0IbBkicbkzz1X4+6hUrWqXiDWroWHHtJH/frht9OIE1JSdLqtvFKcTjpJU7vyEvpg\nUytBhb127SNC36yZpl8VFBs0FZPYDFNBsnmz5sqXLaspkQWZ+OL44+Guu8JmmhGPbNyonsOgQXm3\nDXbgVLCplV7q1tW4Ynp6+G4tbdBUTGIefRAcOKC1ZjIydJo8G0hkFBhvVbm8OmK9tGunI2i3bAnc\n5qefdMBSzZrB7bNOHS2YtmdPeOLzYB59jBKU0ItIVxFZLiJpInLUbJ0iUktEUkRkoYj8JiLdPMvr\niMgeEVnkebwQ7hMoDG66Sf+XkyerY2UYBSYlBcqVgxYtgmuf18CpP/7QAR1Dhmg+fDD4DtDq2DG4\nbfKicmW93TWhjynyFHoRKQo8B1wINAH6i0jO4T33ADOccy2Ay4FJPuvSnXPNPY+4yxifNElL844e\nDf/6V7StMRKGlBT1ooMV5bwGTo0fryGeu+8O3gav0DdurAIdDooW1cFaJvQxRTAefRsgzTm3yjm3\nH5gG9MzRxgHlPK+PAxIiQPf113DjjTro6aGHom2NkTBkZGhx/7zSKn0pUybwwKlVq+C11zTOHmzY\nBo7k0ocrbOPFculjjmCE/kRgnc/7DM8yX8YBV4pIBvAZcIPPurqekM53IuL3/lBEhotIqoikbtq0\nKXjrI0hamsblGzXSfHkr05ukLFmiMexwEmp83ssZZ/gfOHX//XpnEGoPf+PG+gh32VQT+pgjXJ2x\n/YEpzrkaQDfgTREpAvwJ1PKEdG4F3haRcjk3ds695Jxr7ZxrXTlct5D5xDnt87r4Yr1TnjVLQ6lG\nErJ/v5YFGD06vPtNSdFKj8EOxPDSrp1WmVy69MiyFSvgzTfh2mt1sFIolCmjF7JQ7iyCoXp1E/oY\nIxihzwR87wdreJb5chUwA8A59yNQEqjknNvnnNvsWT4fSAcaFNTocHLgAMybBxMnaimCqlXVi09P\n1/LB9epF20Ijaqxfr978a6/B9u3h229KCnTuHHqOrr+BU/fdpwOf7jwqRyJ6VKumBdMOHoy2JYaH\nYH5p84D6IlJXRIqjna2zcrRZC5wDICKNUaHfJCKVPZ25iEg9oD6wKlzG54cDB/R/8tBDWozs+ON1\nQp1bb9Xa8l27wksvqVffqVM0LTWijrcS3a5dOngiHKxerUOkQw3bgObHV6x4ROiXLNGa2DfcACec\nEB77wkG1anprvHFjtC0xPOTZ5e+cOygiI4EvgaLAq865xSJyPzrr+CzgNmCyiNyCdswOds45ETkL\nuF9EDgBZwAjnXC6JwJEhLU1rxX/zDfzf/2nZENCJN4YO1cyyDh1Cv/M1Ehyv0FepopXpbrihYCPl\nIP/xeTgycMo7h+y4cVpCYdSogtkUbnxz6W3QSUwQVG6Xc+4ztJPVd9kYn9dLgKMKZTjn3gfeL6CN\nBeaCCzQxoVEjTZE8+2z11qPcHWDEOl6hHzMGrr9eK9F17VqwfaakqPed3wkI2rWDTz/VuSDffRfu\nuUfLI8QSNmgq5kj4kbG7d6vIjxmjfViTJkHv3ibyRhBkZGgJ0quv1s6bZ54p2P6cU6Hv0iXvevGB\n8MbpBwzQaQdvvbVgNkUCE/qYI+GF3lv/PRZmcDLijMxMDT0UL65zPX7+efYJBUJl5UrdZ37CNl7a\ntNHwUWaminwsTgnmnd3KhD5mSHihX7lSn61KpBEymZlQo4a+vuYaHUzx3HP5319B4vNeypTRzqUK\nFbSUaixSvLiGk0zoY4aEF/oVK/TZhN4IGa9HDxqO6N1bUy29vfmhkpKi+yvoj/HFF3XWmlge4GGD\npmKKpBD6qlW1vLBhBI1z2YUeNOtm+3Z466387a+g8XkvbdtqmlgsY4OmYoqEF/qVK6FBTA3RMuKC\nv//WkbG+Qt+uHbRsqbPCOxfa/pYs0UFEBQnbxBPVqllN+hgi4YV+xQoTeiMfeFMrfYVeRL36xYuP\nxNuD5Ysv9Dnc5QZilWrVdMBUVla0LTFIcKHftg02bbL4vJEPvELv7Yz1cvnl2tH47LOh7W/6dGjV\n6kjFyESnWjUtgfD339G2xCDBhd6bcWMevREy/jx60Loyw4ZpZ+gffwS3r1WrtKBSv37htTGWsVz6\nmCIphN48eiNkMjI0X71q1aPXjfDMn/P888Hta8YMfQ53OeBYxoQ+pkhooV+xQsOqJ50UbUuMuCMz\nUwf++JsBqlYtuOQSnVsymFr106drjZratcNvZ6xiQh9TJLzQ16qld9uGERI5UytzcsMNOlH3O+/k\nvp8VK7QsajKFbcCEPsZIaKG31Eoj3/iOivVHp05w6qla/ya3VMvp0/W2sk+f8NsYy5QqpbV4TOhj\ngoQVeucstdIoAHl59N5Uy0WLYO7cwO2mT9fBTclYrtdGx8YMCSv0mzbBjh3WEWvkg927YevWvMV5\nwACduSZQVcvFi/WRbGEbL9Wr26CpGCFhhd5b48Y8eiNkAqVW5uTYY3Xmmvff9y9o06dr5k7v3uG3\nMR4wjz5mSFiht9RKI98EK/SgE5IcOgQvvJB9uXMq9J07Hynbm2x4hT7UchFG2ElYoV+xQjPjkmUg\nohFGAo2K9Ue9enDRRVpRct++I8sXLdIfYbKGbUCFft8+HaJuRJWEFvqTTvKfBm0YuRKKRw/aKfvX\nXzq1n5fp07V+fa9e4bcvXrAUy5ghYYV+5UoL2xj5JCNDa72XKRNc+3PP1c4gb6esN2xz7rmxN59r\nYWJCHzMkpNBnZVkOvVEA8kqtzEmRIjByJPzyiz7mzYM1a5I7bAMm9DFEQgp9Zibs3WsevZFPQhV6\ngEGD9A7g2WfVmy9WTMskJDMm9DFDQkawLbXSKBCZmRp2CYVy5WDwYHjpJZ2w+4ILYnPi7sKkbFko\nXdpy6WOAhPToLbXSyDeHDqkHmp+RrCNH6qxUGzda2AZ09LBNKRgTJKTQr1ihpTaScdS5UUA2blSx\nz8+Pp2FDOP98raLXo0f4bYtHbNBUTJCwoZv69bWPzDBCItTUypy88opOSFKuXPhsimeqVYOFC6Nt\nRdKTkFJoqZVGvimo0NeoAe3bh8+eeMc8+pgg4YT+4EGduc06Yo18EcqoWCNvqlWDf/7RhxE1Ek7o\n16xRsTeP3sgXmZmaGlm5crQtSQwsxTImSDiht9RKo0BkZKg4WQdPeKhZU5+XLo2uHUlOwv2avamV\nJvRGvsjPYCkjMO3baxmI11+PtiVJTcIJ/YoVOoNZMpcYMQqACX14KV5cRw3PmqWpq0ZUSEihb9BA\nx2oYRsjkNVesETpXX60dZ+bVR42EE3pLrTTyzY4dmh1iHn14adRI5819+WWbhCRKJJTQ790La9da\nfN7IJxkZ+mxCH36GDVMvbM6caFuSlCSU0Kenq8NgHr2RLwo6WMoITO/eOlr45ZejbUlSEpTQi0hX\nEVkuImkicqef9bVEJEVEForIbyLSzWfdXZ7tlovIBeE0PieWWmkUCBP6yFG6NAwYAO+9B1u3Rtua\npCNPoReRosBzwIVAE6C/iDTJ0eweYIZzrgVwOTDJs20Tz/tTgK7AJM/+IoJVrTQKhAl9ZBk2TOOr\nU6dG25KkIxiPvg2Q5pxb5ZzbD0wDeuZo4wBvFafjAG8B6p7ANOfcPufcaiDNs7+IsGIFnHCCplca\nRshkZEDFilp90gg/LVpAy5YwebJ1yhYywQj9icA6n/cZnmW+jAOuFJEM4DPghhC2RUSGi0iqiKRu\n2rQpSNOPxptaaRj5wnLoI8/VV8Nvv0FqarQtSSrC1RnbH5jinKsBdAPeFJGg9+2ce8k519o517py\nAWqMWGqlUSBM6CPPFVfoZBHWKVuoBCPGmUBNn/c1PMt8uQqYAeCc+xEoCVQKctuwsGMHbNhgHr1R\nAEzoI89xx0HfvvD221bRshAJRujnAfVFpK6IFEc7V2flaLMWOAdARBqjQr/J0+5yESkhInWB+sAv\n4TLel4MH4Y47oFOnSOzdSHj274e//rJRsYXBsGEq8jNmRNuSpCFPoXfOHQRGAl8CS9HsmsUicr+I\neOdLuw0YJiK/Au8Ag52yGPX0lwBfANc75w5F4kQqVIBHHoF27SKxdyPh+fNP7SA0jz7ynHmmjpa1\n8E2hEdRUgs65z9BOVt9lY3xeLwH8TqvjnBsPjC+AjYYReSy1svAQ0U7ZUaNg8WI45ZRoW5TwJNTI\nWMPINyb0hcvAgfr84YfRtSNJMKE3DDChL2wqV4batWHJkmhbkhSY0BsGqNCXLKmdPUbhcMopJvSF\nhAm9YYCOij3xRJvIoDBp0gSWLYNDEcnPMHwwoTcMsBz6aNCkCezbB6tWRduShMeE3jDAhD4aNPHU\nRrTwTcQxoTcM50zoo0HjxvpsQh9xTOgNY8sWDSHYqNjCpVw5/cxN6COOCb1h2BSC0aNJExP6QsCE\n3jBWr9bnOnWiakZS0qQJLF0KWVnRtiShMaE3jLQ0fT7ppOjakYyccgrs2QN//BFtSxIaE3rDSEvT\nmaXKl4+2JcmHZd4UCib0hmEz1kQPb+bN4sXRtSPBMaE3jLQ0OPnkaFuRnJQvD9WqmUcfYUzojeRm\n715Yt86EPppY5k3EMaE3kpvVq3XAlIVuoodX6J2LtiUJiwm9kdysXKnP5tFHjyZNYNcuvbMyIoIJ\nvZHceFMrTeijh2XeRBwTeiO5SUvTDkGrQx89vFMJmtBHDBP6ROCyy+C996JtRXxiqZXRp2JFOOEE\nE/oIYkIf72zdCh98AFOmRNuS+MRSK2ODJk0slz6CmNDHO+np+jx3rtULCZV9+2DtWhP6WMAybyKK\nCX284+1M3LpVi0MZwbNmjV4cLXQTfZo0gR07YP36aFuSkJjQxztejx7ghx+iZ0c8YqmVsYNl3kQU\nE/p4Jz0dqlbVziwT+tCw1MrYIRihHz0azjjDQpT54JhoG2AUkLQ0La97wgnwf/8XbWvii7Q0OO44\nzfowossJJ2iKayCh37ABnn5a+1VmzYJLLilc++Ic8+jjnfR09Ujbt4dVq/QPYQRHWprG50WibYkh\novn0gYT+6adh/369e330Ueu0DRET+nhmzx7tvDrpJOjQQZdZ+CZ4Vq60sE0s4U2xzCniO3fCpEnQ\nqxfccw/89JPdvYaICX08s2qVPp90ErRoASVL2h8gWPbv16wbE/rYoUkTzR7buDH78pdegu3b4Y47\nYMgQqFRJvfp4ZccOOHiwUA9pQh/P+HYmFi8ObdqYRx8sf/yhnXom9LGDvw7Z/fth4kTo0gVOPx1K\nl4Ybb4RPP4Xff4+OnQVhzx5o1AhGjCjUw5rQxzPe1ErvXKcdOsCCBVoJ0Mgd70XScuhjB39CP3Uq\nZGaqN+/l+utV8B9/vHDtCwfvvAN//gmvvALz5xfaYU3o45n0dM0a8Rbkat8eDh2CX36Jrl3xgOXQ\nxx7Vqunv2Sv0WVkq5s2awfnnH2lXoQIMGwZvv60jm+MF5+CZZ6BhQ6hcGW65pdA6lU3o4xlvnRZv\n1ki7dvps4Zu8SUuDsmX1D2fEBiLZZ5v65BMd7T169NGZUbfeqs9PPlm4NhaEuXNh0SK4+WZ44AH4\n/nutU1UImNDHM+npR8I2oOV2Tz3VOmSDwVIrYxNfoX/0UahdG/r2PbpdrVrQv7921G7ZUrg25pdn\nntE7liuvhKuu0v/q7bfr2IAIY0Ifrxw8qB2KvkIPGr758UcN4RiBsdTK2OSUU2DTJpg5Uz3g226D\nYwKM67z9du2PmjSpcG3MD+vXw/vvw9ChUKaMntMTT+hUlk89FfHDm9DHK2vXqtj7E/odO6zka24c\nOGCplbGKt0N25EgdsTx0aOC2TZtCt246mGrPnsKxL7+88II6X9dff2TZeedB9+7w4IPw118RPXxQ\nQi8iXUVkuYikicidftZPFJFFnscKEdnms+6Qz7pZ4TQ+qQlUp8U7cMrCN4HxXiRN6GMPr9BnZsIN\nN8Cxx+be/o479A4gludj2LcPXnxRL0o5HbMJE/QiNWZMRE3IU+hFpCjwHHAh0AToLyJNfNs4525x\nzjV3zjUHngF8exj2eNc553qE0fbkJmdqpZc6dTR7wTpkA2OplbFLjRoa2ihVKrv3G4iOHaFtWxXM\nQoh154v33lOP/YYbjl7XsCFcdx1Mngz/+1/ETAjGo28DpDnnVjnn9gPTgJ65tO8PvBMO44xcSE+H\nEiWgevXsy0U0fGNCHxhLrYxdRLSj8r77dARsMO3vu09HiV99dWzWwHnmGWjQQEM1/hg7Vjtpb7st\nYvYHI/QnAut83md4lh2FiNQG6gLf+CwuKSKpIvKTiPgtOSciwz1tUjdt2hSk6UmOt2plET9fYYcO\n2lGbkVH4dsUDaWnqNVapEm1LDH88+aR2tAbLBRfA+PHw1lsa744l5s2Dn3/WuxN//1XQcQFjx8Ls\n2fDZZxExI9ydsZcD7znnfFM+ajvnWgNXAE+KyEk5N3LOveSca+2ca13Z8pqDI2dqpS/t2+uzefX+\nyTn+wIh/7roLBg3SWPc7MRRQeOYZdSoGD8693XXXqdd/xx0R8eqDEfpMoKbP+xqeZf64nBxhG+dc\npud5FfAt0CJkK43sOKe3qoGEvlkzHSJuQu8fmxA88RDRDs+zztLCZ3PnRtsijctPn64XoHLlcm9b\nrBi89hpMmxYRByQYoZ8H1BeRuiJSHBXzo7JnRKQRUB740WdZeREp4XldCWgP2FxhBWXDBti9O7DQ\nFyumM/FY5s3RHDyoF0kT+sSjRAkdaVqzpk5Msnp1dO2ZPFmLso0cGVz7M8/UQVQRIE+hd84dBEYC\nXwJLgRnOucUicr+I+GbRXA5Mcy7bfUdjIFVEfgVSgEeccyb0BSWYKfDat4dff9Va3sYR1q3TPHoT\n+sSkYkUtnXDwIFx0EWzblvc2keDgQXj+ee2AbdQoOjb4ENRUgs65z4DPciwbk+P9OD/bzQWaFsA+\nwx+BUit9ad9ei0L9/DOce27h2BUPWGpl4tOwoY5CPf98LZ/w6ad6l1uYfPONjgV45pnCPW4AbGRs\nPJKerj34tWsHbtOunbax8E12bELw5KBLF43Zz54dnUlKPvxQB3t17Vr4x/aDCX08kp6uIl+8eOA2\n5crBaafBt98WmllxwcqVOhinWrVoW2JEmqFDoU8frRS5fHnhHffQIRX6Cy/U31oMYEIfj3hz6POi\ne3cthZpzarZkxlIrk4unn9YMtOHDNZRZGPz0k/7nevUqnOMFgQl9PJJbDr0v/frpj/u99yJvU7zg\nLU9sJAdVq2p5hDlzdFanwuDDD/Vu+6KLCud4QWBCH29s3ar1t4MR+lNP1SJR06dH3q544NAhvUha\nfD65GDoUOnfW0bZ//pl72x9+0Ok484tzmuJ5zjl5584XIib08YY34yZYserXTztkMwONcUsiMjI0\nr9mEPrkQ0QlK9u71PnA4fQAACdRJREFUX1gM9M533DgtH9KpE/z2W/6O9euvmr8fQ2EbMKGPP4JJ\nrfSlXz/1Mt59N3I2xQuWWpm81K+v9WTefx8++ij7ui1b4OKLtTjaFVdogbHu3fP2/v3x4Yea7dYj\ntgr1mtDHG16hr1cvuPYNG2pJBAvf6HydYB59sjJqlGaiXX+9Ts4D+pto3VrTMCdN0sJoH38Mmzer\nWO/eHdoxPvhA7wpOOCH89hcAE/pQWLdOr/jRHFqdnq4dTGXKBL9Nv36aCfDHH5GzK9bZt0+rIrZr\nByf6Lb5qJDrFimlZgvXrtQjam2/q72HfPvjuO7j2Wg3ztGihhdHmz4eBA4PP1lm5En7/PebCNmBC\nHxqjRukP4JZbomdDsKmVvvTrp88zZoTfnnhh8mSN0T/wgKVWJjNt2sCNN6r3PnCgTlqyYIEKvi89\nesB//qOhnrvvDm7fH36oz5f4rcYeVcTFWKH+1q1bu9TU1GibcTQ//KC3ZA0awIoVOsS5S5fCt6NG\nDe3Rf/310LY7/XSN1cfiZxtp9uzRi2P9+jqAzIQ+ufnnH53W74wz4KGHAk8+7px6+S++CK++qlUx\nc+OMM7TGTZT+YyIy31MS/ijMow+GrCz14qtX1/KntWvr+0OH8t42nOzZo9kzoXr0AJdfrrei3g7J\nZOKFF7Rj7f77TeQNDXvOmQOPPRZY5EF/K888o4XJhg/PfZR5ZqbWlbr00rCbGw5M6IPh7bd1ppiH\nH9bqeI8+qmlUhT0h8apV+pyfzsS+ffU52cI3u3bBI4/oXVCnTtG2xog3ihXT/0z9+hqS+eUX/+1m\nztTnGIzPgwl93uzerR03rVvDlVfqsr59tXb03XcXbhngUFMrfalZU21Otuyb557TCSAeeCDalhjx\nyvHHwxdfqJN33nnw449Ht/ngAy1H3Lhx4dsXBCb0eTFhgnbiPfHEkTkfRWDiRK1n8cgjhWdLQYQe\ntFP2t99g2bLw2eSP3bt17s6xY7X2e7TYuVNvzy+88OjONsMIhVq1NDOnShUtf/z990fWbd6s62I0\nbAMm9LmTmalhmt69oWPH7OvatIEBA7RnvrDSFtPTdTBHxYr52753b71IRcqrd07r6jRuDPfeqzHx\nc87RGbGiwVNP6Z/wvvuic3wjsahRQ+P0NWpo+eGUFF3+8cfaXxejYRswoc+du+/WXvRA9awffli9\n/DvvLBx7vKmV+e1QrF5d59ScPj38ExAvXqwTnPTpA+XLa2fX1KmagdCyZeHP4bltm16Ee/TQjCPD\nCAfVq6vY16mjRcu++urI9IWtWkXbuoCY0Adi/nxNYbz55sCjUGvW1Nz6adP8x+3yS6BwR7BVK3Oj\nXz9YulQHdoSDbdv0M2rWDBYu1Jh4aqreAV1xhQ7UKl1aO0KffTYiM9z7ZeJEtc28eSPcVKmiYn/y\nyVoq4csvNWwTyxldzrmYerRq1cpFnaws5zp2dK5yZee2b8+97c6dzlWr5lzbts4dOhT6cf74w7kP\nP3Tu3nudu+gi56pWdU7EuYYNnevf37nHH3fu66+d27TJuWOOce6uu/J/Xs45t3Gjc0WKOHf33aFv\nu3u3cz/95Nxzzzl31VXOtWjhXLFiau+IEc79/bf/7bZuda57d+fAuSuvdG7XroKdQ178/bdzZcs6\nd9llkT2Okdxs2uRc8+b6u/7222hb44BUF0BXE2fA1JYtR8fR88vBgzoo6oUX4Jpr8m4/ZYoOpqhf\nP7S5Kf/6C/7+W18XKaIlhVu21DuFxYt1xN7atdm3eflluOqq4I/hD2/mQG5TEeZk/34t/eAdO1Cx\not6qtmihOfrNm+e+fVYWjB+vHbRVqkCFCvm3Py927ND+ld9+01LNhhEptm3T6rAXXRR1jz63AVNB\nTQ4eFxQtqkIZLnr1Cl5QBw7UsEqo2Szt2qmwt2ypxZZKlz66zaZNGhJZsEDz6Lt3D+0Y/hg3Tjsq\nQ7nIFykC/fsfsbdmzdB+2EWKaAdt27Y6yjDSg83OPNNE3og8xx8fnv9khEkcj94wDCOJsRIIhmEY\nSYwJvWEYRoJjQm8YhpHgmNAbhmEkOCb0hmEYCY4JvWEYRoJjQm8YhpHgmNAbhmEkODE3YEpENgF5\n1f2tBPxdCObEIsl67nbeyYWdd+jUds5V9rci5oQ+GEQkNdAIsEQnWc/dzju5sPMOLxa6MQzDSHBM\n6A3DMBKceBX6l6JtQBRJ1nO3804u7LzDSFzG6A3DMIzgiVeP3jAMwwgSE3rDMIwEJ+6EXkS6ishy\nEUkTkTujbU+kEJFXReQvEfndZ1kFEZktIis9z+WjaWMkEJGaIpIiIktEZLGI3ORZntDnLiIlReQX\nEfnVc973eZbXFZGfPb/36SJSPNq2RgIRKSoiC0XkE8/7ZDnvNSLyPxFZJCKpnmVh/63HldCLSFHg\nOeBCoAnQX0TCOH9gTDEF6Jpj2Z3A1865+sDXnveJxkHgNudcE+AM4HrPd5zo574PONs51wxoDnQV\nkTOAR4GJzrmTga1AAScMjlluApb6vE+W8wbo4pxr7pM/H/bfelwJPdAGSHPOrXLO7QemAT2jbFNE\ncM7NAbbkWNwTeN3z+nXgkkI1qhBwzv3pnFvgeb0T/fOfSIKfu1P+8bwt5nk44GzgPc/yhDtvABGp\nAVwEvOx5LyTBeedC2H/r8Sb0JwLrfN5neJYlC1Wcc396Xm8AqkTTmEgjInWAFsDPJMG5e8IXi4C/\ngNlAOrDNOXfQ0yRRf+9PAqOBLM/7iiTHeYNezP8rIvNFZLhnWdh/68cUdAdGdHDOORFJ2NxYESkD\nvA/c7JzboU6ekqjn7pw7BDQXkeOBD4FGUTYp4ohId+Av59x8EekcbXuiQAfnXKaInADMFpFlvivD\n9VuPN48+E6jp876GZ1mysFFEqgF4nv+Ksj0RQUSKoSI/1Tn3gWdxUpw7gHNuG5ACtAOOFxGvQ5aI\nv/f2QA8RWYOGYs8GniLxzxsA51ym5/kv9OLehgj81uNN6OcB9T098sWBy4FZUbapMJkFDPK8HgR8\nFEVbIoInPvsKsNQ594TPqoQ+dxGp7PHkEZFSwHlo/0QK0NvTLOHO2zl3l3OuhnOuDvp//sY5N4AE\nP28AETlWRMp6XwPnA78Tgd963I2MFZFuaEyvKPCqc258lE2KCCLyDtAZLVu6ERgLzARmALXQUs59\nnXM5O2zjGhHpAHwP/I8jMdt/o3H6hD13ETkN7XgrijpgM5xz94tIPdTTrQAsBK50zu2LnqWRwxO6\nGeWc654M5+05xw89b48B3nbOjReRioT5tx53Qm8YhmGERryFbgzDMIwQMaE3DMNIcEzoDcMwEhwT\nesMwjATHhN4wDCPBMaE3DMNIcEzoDcMwEpz/B/dEznJJ5NWvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j9vvd1aqXnvigAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo55QKhVeiDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}